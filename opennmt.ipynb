{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99AZe0DtoeU3",
        "outputId": "e018bfb5-dc6f-427d-bb8d-18c07e9fc04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0cP81CdpRhX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p nmt\n",
        "%cd nmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkzna_qQzdjT"
      },
      "outputs": [],
      "source": [
        "!pip3 install SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blL2JaL0pS_v"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zvmVQ4MpXFF"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/en-nl.txt.zip\" /content/nmt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnP0Rxcfri2U"
      },
      "outputs": [],
      "source": [
        "!unzip en-nl.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEOl-IDQyBvd"
      },
      "outputs": [],
      "source": [
        "# Filter the text\n",
        "!python MT-Preparation/filtering/filter.py Europarl.en-nl.en Europarl.en-nl.nl en nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jbU5Z8ozfsx"
      },
      "outputs": [],
      "source": [
        "!python MT-Preparation/subwording/1-train_unigram.py Europarl.en-nl.en-filtered.en Europarl.en-nl.nl-filtered.nl --train_extremely_large_corpus=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwxDxWpS3zeh"
      },
      "outputs": [],
      "source": [
        "!python MT-Preparation/subwording/2-subword.py source.model target.model Europarl.en-nl.en-filtered.en Europarl.en-nl.nl-filtered.nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_37CJ-HSL9e2"
      },
      "outputs": [],
      "source": [
        "!python MT-Preparation/train_dev_split/train_dev_test_split.py 200000 2000 Europarl.en-nl.nl-filtered.nl.subword Europarl.en-nl.en-filtered.en.subword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxHONDORN6tt",
        "outputId": "6cdca1d5-21e9-4650-f8c0-170c8c4025f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   200000 Europarl.en-nl.en-filtered.en.subword.dev\n",
            "     2000 Europarl.en-nl.en-filtered.en.subword.test\n",
            "  1757612 Europarl.en-nl.en-filtered.en.subword.train\n",
            "   200000 Europarl.en-nl.nl-filtered.nl.subword.dev\n",
            "     2000 Europarl.en-nl.nl-filtered.nl.subword.test\n",
            "  1757612 Europarl.en-nl.nl-filtered.nl.subword.train\n",
            "  3919224 total\n"
          ]
        }
      ],
      "source": [
        "!wc -l *.subword.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW0XJTMzOF02",
        "outputId": "c47dd402-1001-4361-efb7-0b3287b78c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/nmt/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp -R /content/nmt/ /content/drive/MyDrive/nmt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8suVHX0GgeZ",
        "outputId": "bef3fdad-7690-4e8e-8432-5ad5614cf745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#to import all the stuff back\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -R /content/drive/MyDrive/nmt2 /content/nmt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WxAS-_fzObQZ"
      },
      "outputs": [],
      "source": [
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: Europarl.en-nl.en-filtered.en.subword.train\n",
        "        path_tgt: Europarl.en-nl.nl-filtered.nl.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: Europarl.en-nl.en-filtered.en.subword.dev\n",
        "        path_tgt: Europarl.en-nl.nl-filtered.nl.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: source.model\n",
        "tgt_subword_model: target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.ennl\n",
        "\n",
        "# Stop training if it does not improve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 200000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 10000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 4000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 2048   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 1024\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "# warmup_steps:\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6  # Increased from 6 to 8\n",
        "dec_layers: 6  # Increased from 6 to 8\n",
        "heads: 8      # Increased from 8 to 12\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "\n",
        "'''\n",
        "\n",
        "file_path = \"/content/nmt/config.yaml\"\n",
        "\n",
        "with open(file_path, \"w+\") as config_yaml:\n",
        "    config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJreUTQ8Y73k",
        "outputId": "21caa3e6-77aa-4bf8-f675-be2fa7f87679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "!nproc --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SjvPLTu7MOZ"
      },
      "outputs": [],
      "source": [
        "!pip3 install OpenNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfU2gRHHX90y",
        "outputId": "62c4dfa8-4412-491e-ab1d-c32af27509c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nmt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVeK4etMY-id",
        "outputId": "e0a163fc-5ea1-4362-92c5-c8dad7bd561d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-31 20:14:57.799871: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-31 20:14:57.799943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-31 20:14:57.799981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-31 20:14:57.808324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-31 20:14:59.297716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-31 20:15:00.985387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-31 20:15:00.985927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-31 20:15:00.986118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-10-31 20:15:01,912 INFO] Counter vocab from -1 samples.\n",
            "[2023-10-31 20:15:01,913 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2023-10-31 20:16:54,843 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=334)\n",
            "\n",
            "[2023-10-31 20:16:55,809 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=303)\n",
            "\n",
            "[2023-10-31 20:16:56,029 INFO] Counters src: 50314\n",
            "[2023-10-31 20:16:56,029 INFO] Counters tgt: 50336\n"
          ]
        }
      ],
      "source": [
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfly9LR602lj",
        "outputId": "5047bab7-f2a7-4461-e942-3855a7aed215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-31 20:17:18.262522: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-31 20:17:18.262573: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-31 20:17:18.262612: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-31 20:17:18.273806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-31 20:17:19.888575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-31 20:17:21.528197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-31 20:17:21.528616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-31 20:17:21.528802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-10-31 20:17:22,046 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-10-31 20:17:22,046 INFO] Parsed 2 corpora from -data.\n",
            "[2023-10-31 20:17:22,046 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2023-10-31 20:17:22,245 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁the', ',', '.', '▁of', '▁to', '▁and']\n",
            "[2023-10-31 20:17:22,246 INFO] The decoder start token is: <s>\n",
            "[2023-10-31 20:17:22,246 INFO] Building model...\n",
            "[2023-10-31 20:17:23,828 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2023-10-31 20:17:23,828 INFO] Non quantized layer compute is fp16\n",
            "[2023-10-31 20:17:31,548 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=50000, bias=True)\n",
            ")\n",
            "[2023-10-31 20:17:31,552 INFO] encoder: 44487680\n",
            "[2023-10-31 20:17:31,553 INFO] decoder: 76435280\n",
            "[2023-10-31 20:17:31,553 INFO] * number of parameters: 120922960\n",
            "[2023-10-31 20:17:31,554 INFO] Trainable parameters = {'torch.float32': 120922960, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-10-31 20:17:31,554 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-10-31 20:17:31,554 INFO]  * src vocab size = 50000\n",
            "[2023-10-31 20:17:31,554 INFO]  * tgt vocab size = 50000\n",
            "[2023-10-31 20:17:32,096 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2023-10-31 20:17:32,096 INFO] Starting training on GPU: [0]\n",
            "[2023-10-31 20:17:32,097 INFO] Start training loop and validate every 10000 steps...\n",
            "[2023-10-31 20:17:32,097 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2023-10-31 20:18:45,847 INFO] Step 100/200000; acc: 4.9; ppl: 29844.8; xent: 10.3; lr: 0.00004; sents:   24939; bsz: 1784/1880/62; 9677/10194 tok/s;     74 sec;\n",
            "[2023-10-31 20:19:29,003 INFO] Step 200/200000; acc: 6.2; ppl: 4750.9; xent: 8.5; lr: 0.00007; sents:   22642; bsz: 1769/1888/57; 16400/17501 tok/s;    117 sec;\n",
            "[2023-10-31 20:20:15,990 INFO] Step 300/200000; acc: 11.0; ppl: 1363.8; xent: 7.2; lr: 0.00011; sents:   22784; bsz: 1767/1885/57; 15040/16046 tok/s;    164 sec;\n",
            "[2023-10-31 20:20:59,856 INFO] Step 400/200000; acc: 14.8; ppl: 864.6; xent: 6.8; lr: 0.00014; sents:   24453; bsz: 1774/1868/61; 16173/17037 tok/s;    208 sec;\n",
            "[2023-10-31 20:21:43,521 INFO] Step 500/200000; acc: 17.5; ppl: 594.2; xent: 6.4; lr: 0.00018; sents:   25345; bsz: 1777/1861/63; 16281/17050 tok/s;    251 sec;\n",
            "[2023-10-31 20:22:27,127 INFO] Step 600/200000; acc: 19.6; ppl: 457.2; xent: 6.1; lr: 0.00021; sents:   23149; bsz: 1755/1856/58; 16103/17026 tok/s;    295 sec;\n",
            "[2023-10-31 20:23:13,465 INFO] Step 700/200000; acc: 22.3; ppl: 359.7; xent: 5.9; lr: 0.00024; sents:   25646; bsz: 1762/1875/64; 15206/16188 tok/s;    341 sec;\n",
            "[2023-10-31 20:23:57,615 INFO] Step 800/200000; acc: 24.2; ppl: 297.1; xent: 5.7; lr: 0.00028; sents:   24605; bsz: 1793/1871/62; 16245/16952 tok/s;    386 sec;\n",
            "[2023-10-31 20:24:41,672 INFO] Step 900/200000; acc: 26.9; ppl: 242.9; xent: 5.5; lr: 0.00031; sents:   24388; bsz: 1764/1873/61; 16020/17005 tok/s;    430 sec;\n",
            "[2023-10-31 20:25:25,670 INFO] Step 1000/200000; acc: 29.3; ppl: 202.7; xent: 5.3; lr: 0.00035; sents:   23944; bsz: 1790/1886/60; 16269/17149 tok/s;    474 sec;\n",
            "[2023-10-31 20:25:25,687 INFO] Saving checkpoint models/model.ennl_step_1000.pt\n",
            "[2023-10-31 20:27:02,996 INFO] Step 1100/200000; acc: 31.9; ppl: 169.2; xent: 5.1; lr: 0.00038; sents:   25406; bsz: 1783/1872/64; 7327/7693 tok/s;    571 sec;\n",
            "[2023-10-31 20:27:47,958 INFO] Step 1200/200000; acc: 34.2; ppl: 143.6; xent: 5.0; lr: 0.00042; sents:   24119; bsz: 1761/1870/60; 15663/16636 tok/s;    616 sec;\n",
            "[2023-10-31 20:28:32,396 INFO] Step 1300/200000; acc: 36.4; ppl: 123.4; xent: 4.8; lr: 0.00045; sents:   23950; bsz: 1790/1875/60; 16116/16881 tok/s;    660 sec;\n",
            "[2023-10-31 20:29:19,056 INFO] Step 1400/200000; acc: 39.1; ppl: 102.9; xent: 4.6; lr: 0.00049; sents:   25257; bsz: 1779/1862/63; 15255/15963 tok/s;    707 sec;\n",
            "[2023-10-31 20:30:06,305 INFO] Step 1500/200000; acc: 41.0; ppl:  89.7; xent: 4.5; lr: 0.00052; sents:   24434; bsz: 1765/1875/61; 14942/15872 tok/s;    754 sec;\n",
            "[2023-10-31 20:30:54,543 INFO] Step 1600/200000; acc: 42.9; ppl:  79.1; xent: 4.4; lr: 0.00056; sents:   24421; bsz: 1768/1887/61; 14657/15651 tok/s;    802 sec;\n",
            "[2023-10-31 20:31:42,654 INFO] Step 1700/200000; acc: 44.3; ppl:  71.3; xent: 4.3; lr: 0.00059; sents:   23906; bsz: 1769/1876/60; 14706/15598 tok/s;    851 sec;\n",
            "[2023-10-31 20:32:30,252 INFO] Step 1800/200000; acc: 45.6; ppl:  64.9; xent: 4.2; lr: 0.00063; sents:   24505; bsz: 1794/1873/61; 15078/15738 tok/s;    898 sec;\n",
            "[2023-10-31 20:33:18,129 INFO] Step 1900/200000; acc: 46.9; ppl:  59.5; xent: 4.1; lr: 0.00066; sents:   24482; bsz: 1792/1870/61; 14974/15622 tok/s;    946 sec;\n",
            "[2023-10-31 20:34:06,502 INFO] Step 2000/200000; acc: 47.7; ppl:  55.8; xent: 4.0; lr: 0.00070; sents:   24781; bsz: 1779/1883/62; 14713/15573 tok/s;    994 sec;\n",
            "[2023-10-31 20:34:06,528 INFO] Saving checkpoint models/model.ennl_step_2000.pt\n",
            "[2023-10-31 20:35:02,215 INFO] Step 2100/200000; acc: 48.7; ppl:  52.3; xent: 4.0; lr: 0.00073; sents:   23791; bsz: 1773/1881/59; 12729/13504 tok/s;   1050 sec;\n",
            "[2023-10-31 20:36:39,869 INFO] Step 2200/200000; acc: 49.1; ppl:  50.3; xent: 3.9; lr: 0.00077; sents:   23877; bsz: 1793/1865/60; 7346/7640 tok/s;   1148 sec;\n",
            "[2023-10-31 20:37:24,408 INFO] Step 2300/200000; acc: 49.6; ppl:  48.4; xent: 3.9; lr: 0.00080; sents:   23575; bsz: 1771/1873/59; 15903/16821 tok/s;   1192 sec;\n",
            "[2023-10-31 20:38:09,339 INFO] Step 2400/200000; acc: 50.0; ppl:  47.1; xent: 3.9; lr: 0.00084; sents:   23999; bsz: 1774/1874/60; 15790/16683 tok/s;   1237 sec;\n",
            "[2023-10-31 20:38:57,416 INFO] Step 2500/200000; acc: 50.9; ppl:  44.5; xent: 3.8; lr: 0.00087; sents:   24027; bsz: 1771/1884/60; 14739/15676 tok/s;   1285 sec;\n",
            "[2023-10-31 20:39:46,290 INFO] Step 2600/200000; acc: 51.5; ppl:  42.7; xent: 3.8; lr: 0.00091; sents:   25095; bsz: 1752/1874/63; 14336/15334 tok/s;   1334 sec;\n",
            "[2023-10-31 20:40:34,990 INFO] Step 2700/200000; acc: 51.9; ppl:  41.6; xent: 3.7; lr: 0.00094; sents:   24437; bsz: 1781/1868/61; 14630/15345 tok/s;   1383 sec;\n",
            "[2023-10-31 20:41:23,410 INFO] Step 2800/200000; acc: 52.0; ppl:  40.6; xent: 3.7; lr: 0.00098; sents:   24967; bsz: 1774/1889/62; 14657/15601 tok/s;   1431 sec;\n",
            "[2023-10-31 20:42:11,558 INFO] Step 2900/200000; acc: 52.8; ppl:  38.8; xent: 3.7; lr: 0.00101; sents:   23592; bsz: 1786/1876/59; 14837/15587 tok/s;   1479 sec;\n",
            "[2023-10-31 20:42:59,852 INFO] Step 3000/200000; acc: 52.6; ppl:  39.4; xent: 3.7; lr: 0.00105; sents:   23945; bsz: 1784/1866/60; 14777/15454 tok/s;   1528 sec;\n",
            "[2023-10-31 20:42:59,891 INFO] Saving checkpoint models/model.ennl_step_3000.pt\n",
            "[2023-10-31 20:43:56,621 INFO] Step 3100/200000; acc: 52.6; ppl:  38.8; xent: 3.7; lr: 0.00108; sents:   23997; bsz: 1770/1863/60; 12475/13129 tok/s;   1585 sec;\n",
            "[2023-10-31 20:44:45,580 INFO] Step 3200/200000; acc: 53.3; ppl:  37.3; xent: 3.6; lr: 0.00112; sents:   25444; bsz: 1773/1884/64; 14488/15391 tok/s;   1633 sec;\n",
            "[2023-10-31 20:46:09,194 INFO] Step 3300/200000; acc: 53.3; ppl:  37.0; xent: 3.6; lr: 0.00115; sents:   24436; bsz: 1795/1874/61; 8588/8967 tok/s;   1717 sec;\n",
            "[2023-10-31 20:46:54,096 INFO] Step 3400/200000; acc: 53.6; ppl:  36.5; xent: 3.6; lr: 0.00119; sents:   23711; bsz: 1789/1875/59; 15938/16699 tok/s;   1762 sec;\n",
            "[2023-10-31 20:47:40,022 INFO] Step 3500/200000; acc: 54.0; ppl:  35.4; xent: 3.6; lr: 0.00122; sents:   24740; bsz: 1790/1879/62; 15589/16362 tok/s;   1808 sec;\n",
            "[2023-10-31 20:48:29,638 INFO] Step 3600/200000; acc: 54.4; ppl:  34.5; xent: 3.5; lr: 0.00126; sents:   24427; bsz: 1780/1880/61; 14347/15158 tok/s;   1858 sec;\n",
            "[2023-10-31 20:49:19,501 INFO] Step 3700/200000; acc: 54.5; ppl:  34.3; xent: 3.5; lr: 0.00129; sents:   25050; bsz: 1773/1878/63; 14225/15068 tok/s;   1907 sec;\n",
            "[2023-10-31 20:50:09,168 INFO] Step 3800/200000; acc: 53.9; ppl:  35.3; xent: 3.6; lr: 0.00133; sents:   23855; bsz: 1755/1865/60; 14138/15017 tok/s;   1957 sec;\n",
            "[2023-10-31 20:50:59,119 INFO] Step 3900/200000; acc: 54.8; ppl:  33.4; xent: 3.5; lr: 0.00136; sents:   23805; bsz: 1792/1882/60; 14350/15074 tok/s;   2007 sec;\n",
            "[2023-10-31 20:51:49,016 INFO] Step 4000/200000; acc: 54.5; ppl:  33.9; xent: 3.5; lr: 0.00140; sents:   24078; bsz: 1778/1880/60; 14253/15075 tok/s;   2057 sec;\n",
            "[2023-10-31 20:51:49,067 INFO] Saving checkpoint models/model.ennl_step_4000.pt\n",
            "[2023-10-31 20:52:48,082 INFO] Step 4100/200000; acc: 54.7; ppl:  33.3; xent: 3.5; lr: 0.00138; sents:   23494; bsz: 1767/1853/59; 11968/12546 tok/s;   2116 sec;\n",
            "[2023-10-31 20:53:35,218 INFO] Step 4200/200000; acc: 55.2; ppl:  32.4; xent: 3.5; lr: 0.00136; sents:   24929; bsz: 1750/1872/62; 14847/15885 tok/s;   2163 sec;\n",
            "[2023-10-31 20:54:24,843 INFO] Step 4300/200000; acc: 55.7; ppl:  31.6; xent: 3.5; lr: 0.00135; sents:   24849; bsz: 1783/1873/62; 14370/15099 tok/s;   2213 sec;\n",
            "[2023-10-31 20:56:03,601 INFO] Step 4400/200000; acc: 55.6; ppl:  31.5; xent: 3.4; lr: 0.00133; sents:   24093; bsz: 1768/1865/60; 7162/7555 tok/s;   2312 sec;\n",
            "[2023-10-31 20:56:52,014 INFO] Step 4500/200000; acc: 56.6; ppl:  29.7; xent: 3.4; lr: 0.00132; sents:   24587; bsz: 1790/1896/61; 14788/15665 tok/s;   2360 sec;\n",
            "[2023-10-31 20:57:40,857 INFO] Step 4600/200000; acc: 56.4; ppl:  29.8; xent: 3.4; lr: 0.00130; sents:   24684; bsz: 1792/1869/62; 14676/15306 tok/s;   2409 sec;\n",
            "[2023-10-31 20:58:30,089 INFO] Step 4700/200000; acc: 56.9; ppl:  29.3; xent: 3.4; lr: 0.00129; sents:   25603; bsz: 1774/1879/64; 14413/15265 tok/s;   2458 sec;\n",
            "[2023-10-31 20:59:19,110 INFO] Step 4800/200000; acc: 56.6; ppl:  29.5; xent: 3.4; lr: 0.00128; sents:   24029; bsz: 1750/1867/60; 14280/15231 tok/s;   2507 sec;\n",
            "[2023-10-31 21:00:09,322 INFO] Step 4900/200000; acc: 56.9; ppl:  29.0; xent: 3.4; lr: 0.00126; sents:   24110; bsz: 1753/1880/60; 13968/14975 tok/s;   2557 sec;\n",
            "[2023-10-31 21:00:58,936 INFO] Step 5000/200000; acc: 57.6; ppl:  27.7; xent: 3.3; lr: 0.00125; sents:   24503; bsz: 1794/1867/61; 14466/15054 tok/s;   2607 sec;\n",
            "[2023-10-31 21:00:58,975 INFO] Saving checkpoint models/model.ennl_step_5000.pt\n",
            "[2023-10-31 21:01:58,584 INFO] Step 5100/200000; acc: 57.5; ppl:  27.7; xent: 3.3; lr: 0.00124; sents:   24430; bsz: 1768/1860/61; 11856/12473 tok/s;   2666 sec;\n",
            "[2023-10-31 21:02:47,569 INFO] Step 5200/200000; acc: 58.1; ppl:  26.8; xent: 3.3; lr: 0.00123; sents:   23982; bsz: 1768/1895/60; 14437/15474 tok/s;   2715 sec;\n",
            "[2023-10-31 21:03:36,264 INFO] Step 5300/200000; acc: 57.6; ppl:  27.4; xent: 3.3; lr: 0.00121; sents:   22585; bsz: 1776/1874/56; 14588/15394 tok/s;   2764 sec;\n",
            "[2023-10-31 21:05:19,781 INFO] Step 5400/200000; acc: 58.4; ppl:  26.2; xent: 3.3; lr: 0.00120; sents:   24610; bsz: 1792/1863/62; 6923/7200 tok/s;   2868 sec;\n",
            "[2023-10-31 21:06:08,334 INFO] Step 5500/200000; acc: 58.0; ppl:  26.8; xent: 3.3; lr: 0.00119; sents:   24144; bsz: 1757/1868/60; 14473/15392 tok/s;   2916 sec;\n",
            "[2023-10-31 21:06:56,965 INFO] Step 5600/200000; acc: 58.5; ppl:  26.1; xent: 3.3; lr: 0.00118; sents:   23551; bsz: 1778/1883/59; 14625/15489 tok/s;   2965 sec;\n",
            "[2023-10-31 21:07:46,054 INFO] Step 5700/200000; acc: 58.5; ppl:  26.0; xent: 3.3; lr: 0.00117; sents:   23072; bsz: 1760/1875/58; 14343/15281 tok/s;   3014 sec;\n",
            "[2023-10-31 21:08:35,598 INFO] Step 5800/200000; acc: 59.3; ppl:  24.9; xent: 3.2; lr: 0.00116; sents:   26001; bsz: 1804/1871/65; 14566/15105 tok/s;   3064 sec;\n",
            "[2023-10-31 21:09:25,298 INFO] Step 5900/200000; acc: 59.2; ppl:  24.9; xent: 3.2; lr: 0.00115; sents:   24242; bsz: 1768/1889/61; 14231/15203 tok/s;   3113 sec;\n",
            "[2023-10-31 21:10:12,236 INFO] Step 6000/200000; acc: 59.1; ppl:  25.1; xent: 3.2; lr: 0.00114; sents:   25310; bsz: 1771/1857/63; 15091/15829 tok/s;   3160 sec;\n",
            "[2023-10-31 21:10:12,256 INFO] Saving checkpoint models/model.ennl_step_6000.pt\n",
            "[2023-10-31 21:11:22,273 INFO] Step 6100/200000; acc: 59.4; ppl:  24.6; xent: 3.2; lr: 0.00113; sents:   25272; bsz: 1794/1861/63; 10247/10631 tok/s;   3230 sec;\n",
            "[2023-10-31 21:12:06,767 INFO] Step 6200/200000; acc: 58.8; ppl:  25.2; xent: 3.2; lr: 0.00112; sents:   22838; bsz: 1791/1867/57; 16105/16781 tok/s;   3275 sec;\n",
            "[2023-10-31 21:12:55,747 INFO] Step 6300/200000; acc: 59.6; ppl:  24.2; xent: 3.2; lr: 0.00111; sents:   24401; bsz: 1791/1886/61; 14623/15400 tok/s;   3324 sec;\n",
            "[2023-10-31 21:13:46,433 INFO] Step 6400/200000; acc: 59.3; ppl:  24.6; xent: 3.2; lr: 0.00110; sents:   24608; bsz: 1745/1876/62; 13771/14803 tok/s;   3374 sec;\n",
            "[2023-10-31 21:14:37,194 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=569)\n",
            "\n",
            "[2023-10-31 21:14:37,194 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n"
          ]
        }
      ],
      "source": [
        "!onmt_train -config config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSmZyESewJwv",
        "outputId": "9561ed46-2e93-4d22-aa2b-fce5080f2de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁ Y ou ▁actively ▁support ▁globalisation ▁but ▁you ▁scream ▁at ▁the ▁top ▁of ▁your ▁voices ▁when ▁European ▁companies ▁try ▁to ▁adapt ▁to ▁the ▁damaging ▁regulations ▁that ▁you ▁yourselves ▁laid ▁down , ▁as ▁well ▁as ▁to ▁the ▁economic ▁environment ▁that ▁you ▁are ▁imposing ▁on ▁them . ▁Have ▁the ▁courage ▁then , ▁to ▁face ▁up ▁to ▁reality .\n",
            "▁It ▁would ▁indeed ▁be ▁ideal ▁to ▁create ▁competition ▁structures ▁which ▁include ▁basic ▁principles , ▁such ▁as ▁restricting ▁abusive ▁practices ▁and ▁concentrations , ▁common ▁principles ▁to ▁prohibit ▁unfair ▁competition ▁in ▁the ▁international ▁sphere , ▁and ▁the ▁development ▁of ▁a ▁cooperation ▁instrument ▁based ▁on ▁experience ▁gained ▁in ▁this ▁field .\n",
            "▁Mr ▁President , ▁the ▁situation ▁in ▁Indonesia ▁is ▁getting ▁worse ▁from ▁week ▁to ▁week , ▁which ▁is ▁not ▁a ▁good ▁omen ▁for ▁the ▁elections ▁on ▁ 7 ▁June .\n",
            "▁This ▁is ▁an ▁instrument ▁of ▁pressure ▁that ▁is ▁difficult ▁to ▁capture ▁precisely .\n",
            "▁To ▁these ▁objectives ▁must ▁be ▁added ▁that ▁of ▁increasing ▁the ▁free ▁movement ▁of ▁food ▁products , ▁in ▁that ▁the ▁creation ▁of ▁a ▁regulation ▁will ▁enable ▁food ▁business ▁operators ▁to ▁be ▁competitive ▁on ▁a ▁fair ▁and ▁equal ▁footing ▁throughout ▁the ▁Member ▁States .\n",
            "▁These ▁are ▁important ▁missions , ▁strongly ▁supported ▁by ▁all ▁the ▁Italian ▁political ▁parties , ▁even ▁though , ▁to ▁be ▁truthful , ▁Mr ▁Prodi , ▁there ▁are ▁some ▁embarrassing ▁exceptions ▁in ▁your ▁governing ▁majority .\n",
            "▁Together ▁we ▁have ▁tried , ▁in ▁the ▁report ▁on ▁the ▁UfM , ▁to ▁support ▁a ▁different ▁vision ▁of ▁our ▁Mediterranean .\n",
            "▁Over ▁the ▁last ▁three ▁years ▁we ▁had ▁Kosovo , ▁where ▁we ▁really ▁had ▁to ▁fight ▁hard ▁to ▁end ▁up ▁with ▁any ▁money ▁at ▁all .\n",
            "▁Now ▁the ▁governments ▁must ▁have ▁their ▁say .\n",
            "▁Many ▁years ▁ago ▁I ▁met ▁some ▁ X injiang ▁people ▁- ▁I ▁cannot ▁remember ▁the ▁individual ▁names ▁- ▁they ▁really ▁used ▁to ▁fight ▁for ▁independence ▁and ▁even ▁if ▁necessary ▁used ▁violence .\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 Europarl.en-nl.en-filtered.en.subword.test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opKvFozOwXkX",
        "outputId": "b888e290-dc26-4a74-d006-7732b0ea9f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dames en heren, u werkt actief mee aan de mondialisering, maar begint meteen te roepen wanneer Europese ondernemingen zich proberen aan te passen aan de schadelijke regels die u zelf hebt afgekondigd en aan de economische omgeving die u hen zelf hebt opgelegd.\n",
            "Dat zou inderdaad de ideale oplossing zijn, waarbij het zaak zou zijn dat er structuren voor de concurrentie werden ontwikkeld op basis van een aantal grondbeginselen zoals de beperking van misbruik en concentratie, gemeenschappelijke principes die concurrentievervalsing op internationaal niveau verbieden, en de ontwikkeling van een instrument ter bevordering van de samenwerking en gebaseerd op de ervaring die op dit gebied is opgedaan.\n",
            "Voorzitter, de situatie in Indonesië verslechtert van week tot week. Dat is geen goed teken voor de verkiezingen van 7 juni.\n",
            "Het gaat om een drukmiddel dat moeilijk te vatten is.\n",
            "Afgezien daarvan hebben wij ook nog het doel van de verbetering van het vrije verkeer van voedingsmiddelen. De opstelling van een verordening zal de bedrijven in staat stellen met elkaar te concurreren onder eerlijke en gelijke voorwaarden in alle lidstaten.\n",
            "Dat zijn belangrijke missies die in Italië sterk worden gesteund door alle politieke groeperingen, met enige gênante uitzonderingen, mijnheer Prodi, in uw eigen regeringscoalitie.\n",
            "Wij hebben samen geprobeerd in het verslag over de Unie voor het Middellandse Zeegebied een andere visie op dat gebied uit te dragen.\n",
            "In de afgelopen drie jaar hebben wij onder andere enorm ons best moeten doen om eindelijk geld voor Kosovo te krijgen.\n",
            "Nu zijn de regeringen weer aan zet.\n",
            "Heel wat jaren geleden had ik een ontmoeting met een aantal mensen uit Xinjiang - hun namen weet ik niet meer - die letterlijk streden voor onafhankelijkheid, zo nodig met geweld.\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 Europarl.en-nl.nl-filtered.nl.subword.test.desubword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkIUuRaL-GbJ",
        "outputId": "8e180df9-7a12-48b4-f0fd-644daf1ac109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-25 16:37:36.904218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-25 16:37:36.904288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-25 16:37:36.907434: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-25 16:37:37.198594: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-25 16:37:40.404551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-25 16:37:44.258628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-25 16:37:44.259201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-25 16:37:44.259410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-10-25 16:37:45,146 INFO] Loading checkpoint from models/model.ennl_step_1000.pt\n",
            "[2023-10-25 16:37:56,288 INFO] Loading data into the model\n",
            "[2023-10-25 16:41:21,755 INFO] PRED SCORE: -1.4169, PRED PPL: 4.12 NB SENTENCES: 2000\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/model.ennl_step_40000.pt -src Europarl.en-nl.en-filtered.en.subword.test -output Europarl.nl.translated -gpu 0 -min_length 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGjgArCw-NVG",
        "outputId": "8c58cdfe-536b-48e8-c71c-9dda9063605e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁In ▁de ▁eerste ▁plaats ▁van ▁de ▁Europese ▁Unie .\n",
            "▁In ▁de ▁eerste ▁plaats ▁van ▁de ▁Europese ▁Unie .\n",
            "▁In ▁de ▁eerste ▁plaats ▁van ▁de ▁Europese ▁Unie .\n",
            "▁In ▁de ▁eerste ▁plaats ▁van ▁de ▁Europese ▁Unie .\n",
            "▁In ▁de ▁eerste ▁plaats ▁van ▁de ▁Europese ▁Unie .\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 Europarl.nl.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqoapy4_-UAB",
        "outputId": "cc5ec863-6505-4020-8e3e-e2f51528c35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done desubwording! Output: Europarl.nl.translated.desubword\n"
          ]
        }
      ],
      "source": [
        "!python MT-Preparation/subwording/3-desubword.py target.model Europarl.nl.translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZK7D4_r-eHJ",
        "outputId": "cd60d410-df0c-4e56-d275-462b8ed1a1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done desubwording! Output: Europarl.en-nl.nl-filtered.nl.subword.test.desubword\n"
          ]
        }
      ],
      "source": [
        "!python MT-Preparation/subwording/3-desubword.py target.model Europarl.en-nl.nl-filtered.nl.subword.test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJnKpuaQ-m02",
        "outputId": "0c0071fe-609d-4231-b9e3-87d208f7ec50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-25 16:43:41--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py’\n",
            "\n",
            "compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-25 16:43:41 (42.5 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download BLEU\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtPUtjP3-o7j",
        "outputId": "d1b414eb-be02-48f8-f2eb-c73643b27905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICpYB10q-qXv",
        "outputId": "099a4f59-d18d-47f2-8714-a52ba7eeba2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference 1st sentence: Dames en heren, u werkt actief mee aan de mondialisering, maar begint meteen te roepen wanneer Europese ondernemingen zich proberen aan te passen aan de schadelijke regels die u zelf hebt afgekondigd en aan de economische omgeving die u hen zelf hebt opgelegd.\n",
            "MTed 1st sentence: In de eerste plaats van de Europese Unie.\n",
            "BLEU:  0.874830770080218\n"
          ]
        }
      ],
      "source": [
        "!python compute-bleu.py Europarl.en-nl.nl-filtered.nl.subword.test.desubword Europarl.nl.translated.desubword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YzqCBXt-umx"
      },
      "outputs": [],
      "source": [
        "!cp -R /content/nmt/ /content/drive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}